---
permalink: /
title: "Welcome to Hanning Zhang's Personal Website"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a first-year MSCS student at the University of Illinois Urbana-Champaign (UIUC), advised by Professor [Tong Zhang](http://tongzhang-ml.org/). Previously, I graduated from The Hong Kong University of Science and Technology (HKUST) in 2024, majoring in Computer Science. Previously, I worked as a research intern on the topic of LLM hallucination and alignment, advised by Professor [Tong Zhang](http://tongzhang-ml.org/). In 2023 Summer, I had the privilege to work as a research intern at [Blender Lab](https://blender.cs.illinois.edu/), advised by Professor [Heng Ji](https://blender.cs.illinois.edu/hengji.html).



Research Interest
------
My research interests include Natural Language Processing (NLP) and Large Language Models (LLMs). I have a broad interest in LLM alignment. I am now working on Reward Modeling for Mathematical Reasoning. I also worked on LLM hallucination in the past.


Open-Source Contribution
------

**RLHF-Reward-Modeling**
<a href="https://github.com/RLHFlow/RLHF-Reward-Modeling" target="_blank">
  <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub Icon" width="24" height="24">
  <span>https://github.com/RLHFlow/RLHF-Reward-Modeling (1K Stars)</span>
</a> 


I am the main contributor to the **math-rm** project, where we train process-supervised reward (PRM) and outcome-supervised reward (ORM) using the next-token prediction. We open-source the data, code, hyper-parameter, and model for a robust recipe that is easy to reproduce.

Research Papers
------
  
* [R-Tuning: Teaching Large Language Models to Refuse Unknown Questions](https://arxiv.org/abs/2311.09677) \
  **<ins>Hanning Zhang\*</ins>**, Shizhe Diao\*, Yong Lin\*, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang. (* denotes equal contribution) \
  **NAACL-2024 (Oral)** \
  <span style="color:red;">**Outstanding Paper Award, 6/2434 = 0.25%**</span>

* [Entropy-Regularized Process Reward Model]() \
  **<ins>Hanning Zhang\*</ins>**, Pengcheng Wang\*, Shizhe Diao, Yong Lin, Rui Pan, Hanze Dong, Dylan Zhang, Pavlo Molchanov, Tong Zhang. (* denotes equal contribution) \
  **Under Review**
  
* [Towards understanding the efficiency of ensemble in fine-tuning]() \
  Yifan Hao, Xingyuan Pan, **<ins>Hanning Zhang</ins>**, Chenlu Ye, Rui Pan, Tong Zhang. \
  **Under Review**
  
* [Mitigating the Alignment Tax of RLHF](https://arxiv.org/abs/2309.06256) \
  Yong Lin\*, Hangyu Lin\*, Wei Xiong\*, Shizhe Diao\*, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, **<ins>Hanning Zhang</ins>**, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, and Tong Zhang \
  **EMNLP-2024 (Main)**
  
* [InfoPattern: Unveiling Information Propagation Patterns in Social Media](https://arxiv.org/abs/2311.15642) \
  Chi Han\*, Manling Li\*, Jialiang Xu\*, **<ins>Hanning Zhang\*</ins>**, Tarek Abdelzaher, Heng Ji (* denotes equal contribution) \
  **Demo Report**


Education
------
* **University of Illinois Urbana-Champaign** (2024-2026) \
  Master of Science in Computer Science
  
* **The Hong Kong University of Science and Technology** (2020-2024) \
  Bachelor of Science in Computer Science

* **University of Illinois Urbana-Champaign** (2023) \
  Exchange Program in Computer Science
