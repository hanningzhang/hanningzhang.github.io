---
permalink: /
title: "Welcome to Hanning Zhang's Personal Website"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year MSCS (thesis-track) student at the University of Illinois Urbana-Champaign (UIUC), advised by Professor [Tong Zhang](http://tongzhang-ml.org/). Previously, I graduated from The Hong Kong University of Science and Technology (HKUST) in 2024, majoring in Computer Science. Previously, I worked as a research intern on the topic of LLM hallucination and alignment, advised by Professor [Tong Zhang](http://tongzhang-ml.org/). In 2023 Summer, I had the privilege to work as a research intern at [Blender Lab](https://blender.cs.illinois.edu/), advised by Professor [Heng Ji](https://blender.cs.illinois.edu/hengji.html).



Research Interest
------
My research interests include Natural Language Processing (NLP) and Large Language Models (LLMs). I have a broad interest in LLM alignment. I am now working on Reward Modeling for Mathematical Reasoning. I also worked on LLM hallucination in the past.


Open-Source Contribution
------

**RLHF-Reward-Modeling**
<a href="https://github.com/RLHFlow/RLHF-Reward-Modeling" target="_blank">
  <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub Icon" width="24" height="24">
  <span>https://github.com/RLHFlow/RLHF-Reward-Modeling</span>
  <span style="color:red;">**1.5K Stars**</span>
</a> 


I am the main contributor to the **math-rm** project, where we train process-supervised reward (PRM) and outcome-supervised reward (ORM) using the next-token prediction. We open-source the data, code, hyper-parameter, and model for a robust recipe that is easy to reproduce. This is **the first open-source recipe of (generative) process reward.**

Selected Research Papers (* denotes equal contribution)
------

* [OpenGenAlign: A Preference Dataset for Trustworthy Reward Modeling in Open-Ended, Long-Context
Generation](https://arxiv.org/abs/2501.13264) \
  **<ins>Hanning Zhang</ins>**, Juntong Song, Juno Zhu, Yuanhao Wu, Tong Zhang, Cheng Niu \
  **Under Review at ACL ARR**
  
* [R-Tuning: Teaching Large Language Models to Refuse Unknown Questions](https://arxiv.org/abs/2311.09677) \
  **<ins>Hanning Zhang\*</ins>**, Shizhe Diao\*, Yong Lin\*, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang. (* denotes equal contribution) \
  **NAACL-2024 (Oral)** \
  <span style="color:red;">**Outstanding Paper Award, 6/2434 = 0.25%**</span>

* [Entropy-Regularized Process Reward Model](https://arxiv.org/abs/2412.11006) \
  **<ins>Hanning Zhang\*</ins>**, Pengcheng Wang\*, Shizhe Diao, Yong Lin, Rui Pan, Hanze Dong, Dylan Zhang, Pavlo Molchanov, Tong Zhang. (* denotes equal contribution) \
  **Transaction of Machine Learning (TMLR)**
  
* [Self-rewarding Correction for Mathematical Reasoning](https://arxiv.org/abs/2502.19613) \
  Wei Xiong*, **<ins>Hanning Zhang*</ins>**, Chenlu Ye*, Lichang Chen, Nan Jiang, Tong Zhang. \
  **Under Review**

* [Online-DPO-R1: Unlocking Effective Reasoning Without the PPO Overhead](https://efficient-unicorn-451.notion.site/Online-DPO-R1-Unlocking-Effective-Reasoning-Without-the-PPO-Overhead-1908b9a70e7b80c3bc83f4cf04b2f175) \
  **<ins>Hanning Zhang</ins>**, Jiarui Yao, Chenlu Ye, Wei Xiong, Tong Zhang. \
  **Notion Blog**

* [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and
RL](https://arxiv.org/abs/2505.02391) \
  Jiarui Yao*, Yifan Hao*, **<ins>Hanning Zhang</ins>**, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang. \
  **NeurIPS-2025**
  
* [ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting](https://arxiv.org/abs/2406.19976) \
  Rui Pan*, Dylan Zhang*, **<ins>Hanning Zhang*</ins>**, Xingyuan Pan*, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang. \
  **ACL-2025**
  
* [Understanding Overadaptation in Supervised Fine-Tuning: The Role of Ensemble Methods](https://arxiv.org/abs/2506.01901) \
  Yifan Hao*, Xingyuan Pan*, **<ins>Hanning Zhang*</ins>**, Chenlu Ye, Rui Pan, Tong Zhang. \
  **ICML-2025**
  
* [Towards Better Generalization via Distributional Input Projection Network](https://arxiv.org/abs/2506.04690) \
  Yifan Hao*, Yanxin Lu*, **<ins>Hanning Zhang</ins>**, Xinwei Shen, Tong Zhang. \
  **Under Review**
  
* [Mitigating the Alignment Tax of RLHF](https://arxiv.org/abs/2309.06256) \
  Yong Lin\*, Hangyu Lin\*, Wei Xiong\*, Shizhe Diao\*, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, **<ins>Hanning Zhang</ins>**, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, and Tong Zhang \
  **EMNLP-2024 (Main)**
  
Internship
------
<div>
  <strong>Amazon Rufus Team</strong>
  <span style="float: right;">May 2025 - Aug 2025</span>
  <br>
  Applied Scientist Intern
  <span style="float: right;">Palo Alto, CA</span>
</div>

Education
------
* **University of Illinois Urbana-Champaign** (2024-2026) \
  Master of Science in Computer Science
  
* **The Hong Kong University of Science and Technology** (2020-2024) \
  Bachelor of Science in Computer Science

* **University of Illinois Urbana-Champaign** (2023) \
  Exchange Program in Computer Science
